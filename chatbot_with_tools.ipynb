{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6a1a508f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-tavily in ./.venv/lib/python3.12/site-packages (0.2.1)\n",
      "Requirement already satisfied: dotenv in ./.venv/lib/python3.12/site-packages (0.9.9)\n",
      "Requirement already satisfied: langgraph in ./.venv/lib/python3.12/site-packages (0.4.8)\n",
      "Requirement already satisfied: langchain in ./.venv/lib/python3.12/site-packages (0.3.25)\n",
      "Requirement already satisfied: IPython in ./.venv/lib/python3.12/site-packages (9.3.0)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.11.14 in ./.venv/lib/python3.12/site-packages (from langchain-tavily) (3.12.12)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in ./.venv/lib/python3.12/site-packages (from langchain-tavily) (0.3.65)\n",
      "Requirement already satisfied: mypy<2.0.0,>=1.15.0 in ./.venv/lib/python3.12/site-packages (from langchain-tavily) (1.16.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.3 in ./.venv/lib/python3.12/site-packages (from langchain-tavily) (2.32.4)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in ./.venv/lib/python3.12/site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in ./.venv/lib/python3.12/site-packages (from langchain) (0.3.45)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./.venv/lib/python3.12/site-packages (from langchain) (2.11.5)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./.venv/lib/python3.12/site-packages (from langchain) (2.0.41)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.venv/lib/python3.12/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (1.20.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./.venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-tavily) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-tavily) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./.venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-tavily) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./.venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-tavily) (4.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-tavily) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.venv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./.venv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./.venv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: mypy_extensions>=1.0.0 in ./.venv/lib/python3.12/site-packages (from mypy<2.0.0,>=1.15.0->langchain-tavily) (1.1.0)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in ./.venv/lib/python3.12/site-packages (from mypy<2.0.0,>=1.15.0->langchain-tavily) (0.12.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.32.3->langchain-tavily) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.32.3->langchain-tavily) (2.4.0)\n",
      "Requirement already satisfied: python-dotenv in ./.venv/lib/python3.12/site-packages (from dotenv) (1.1.0)\n",
      "Requirement already satisfied: langgraph-checkpoint>=2.0.26 in ./.venv/lib/python3.12/site-packages (from langgraph) (2.0.26)\n",
      "Requirement already satisfied: langgraph-prebuilt>=0.2.0 in ./.venv/lib/python3.12/site-packages (from langgraph) (0.2.2)\n",
      "Requirement already satisfied: langgraph-sdk>=0.1.42 in ./.venv/lib/python3.12/site-packages (from langgraph) (0.1.70)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in ./.venv/lib/python3.12/site-packages (from langgraph) (3.5.0)\n",
      "Requirement already satisfied: langchain-ollama in ./.venv/lib/python3.12/site-packages (from langchain[ollama]) (0.3.3)\n",
      "Requirement already satisfied: decorator in ./.venv/lib/python3.12/site-packages (from IPython) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in ./.venv/lib/python3.12/site-packages (from IPython) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./.venv/lib/python3.12/site-packages (from IPython) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in ./.venv/lib/python3.12/site-packages (from IPython) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.12/site-packages (from IPython) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./.venv/lib/python3.12/site-packages (from IPython) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./.venv/lib/python3.12/site-packages (from IPython) (2.19.1)\n",
      "Requirement already satisfied: stack_data in ./.venv/lib/python3.12/site-packages (from IPython) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in ./.venv/lib/python3.12/site-packages (from IPython) (5.14.3)\n",
      "Requirement already satisfied: wcwidth in ./.venv/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->IPython) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./.venv/lib/python3.12/site-packages (from jedi>=0.16->IPython) (0.8.4)\n",
      "Requirement already satisfied: ormsgpack<2.0.0,>=1.8.0 in ./.venv/lib/python3.12/site-packages (from langgraph-checkpoint>=2.0.26->langgraph) (1.10.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.12/site-packages (from pexpect>4.3->IPython) (0.7.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./.venv/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: ollama<1.0.0,>=0.4.8 in ./.venv/lib/python3.12/site-packages (from langchain-ollama->langchain[ollama]) (0.5.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.12/site-packages (from stack_data->IPython) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.12/site-packages (from stack_data->IPython) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in ./.venv/lib/python3.12/site-packages (from stack_data->IPython) (0.2.3)\n"
     ]
    }
   ],
   "source": [
    "# Install the search engine\n",
    "!pip install langchain-tavily dotenv langgraph langchain \"langchain[ollama]\" IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a8231fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  configure the environment\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "# define the tool\n",
    "tool = TavilySearch(max_results = 2)\n",
    "tools = [tool]\n",
    "#tool.invoke(\"What is a node in langgraph?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cd7a6a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model('ollama:llama3.2')\n",
    "llm_with_tools = llm.bind_tools(tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c1ebce7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10fa18620>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining the graph\n",
    "\n",
    "from typing import Annotated, Sequence, TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "# defining the state \n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence, add_messages]\n",
    "\n",
    "\n",
    "def chatbot(state: AgentState) -> AgentState:\n",
    "    response = llm_with_tools.invoke(state.get('messages'))\n",
    "    pprint(response)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "graph_builder = StateGraph(AgentState)\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "graph_builder.add_edge(START, \"chatbot\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6ff64b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10fa18620>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a function to runt the tools (Tool Node function)\n",
    "\n",
    "import json\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "class BasicToolNode:\n",
    "    \"\"\"\n",
    "    A node that runs the tools required in the last AIMessage\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tools: list) -> None:\n",
    "        self.tool_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "    def __call__(self, inputs: dict):\n",
    "        # if messages are present then get the last tool message\n",
    "\n",
    "        if messages := inputs.get(\"messages\", []) :\n",
    "            message = messages[-1]\n",
    "        else:\n",
    "            raise ValueError('No Message found in input')\n",
    "        \n",
    "\n",
    "        outputs = []\n",
    "\n",
    "        # loop over the tool calls and invoke the tool to get the response\n",
    "        for tool_call in message.tool_calls:\n",
    "            tool_result = self.tool_by_name[tool_call.get('name')].invoke(\n",
    "                tool_call.get('args')\n",
    "            )\n",
    "\n",
    "            # append the tool response to outputs list\n",
    "            outputs.append(\n",
    "                ToolMessage(\n",
    "                    content=json.dumps(tool_result),\n",
    "                    name=tool_call.get('name'),\n",
    "                    tool_call_id = tool_call['id']\n",
    "                )\n",
    "            )\n",
    "        \n",
    "\n",
    "        # return the updated state\n",
    "        return {\"messages\": outputs}\n",
    "\n",
    "tool_node = BasicToolNode(tools=tools)\n",
    "\n",
    "# add the tool node to the graph\n",
    "graph_builder.add_node(\"tools\",tool_node )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6573066f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the conditional edge for the graph\n",
    "\n",
    "def route_tools(state: AgentState):\n",
    "    \"\"\"\n",
    "    Use in the graph conditional edge, to route to ToolNode if the last message have tool calls, otherwise route to end node\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(state, list):\n",
    "        ai_message = state[-1]\n",
    "    elif messages := state.get(\"messages\", []):\n",
    "        ai_message = messages[-1]\n",
    "    else:\n",
    "        raise ValueError(f\"No message found in input state to tools_edge: {state}\")\n",
    "    \n",
    " \n",
    "    # check whether the message have tool_calls attribute\n",
    "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
    "        return \"tools\"\n",
    "    \n",
    "    return END\n",
    "\n",
    "\n",
    "# adding conditional edge to the graph\n",
    "graph_builder.add_conditional_edges(\n",
    "    source=\"chatbot\",\n",
    "    path=route_tools,\n",
    "    path_map={\n",
    "        \"tools\": \"tools\",\n",
    "        END: END\n",
    "    }\n",
    ")\n",
    "\n",
    "# adding the edge from tools to chatbot\n",
    "graph_builder.add_edge(\"tools\",\"chatbot\")\n",
    "\n",
    "# compiling the graph\n",
    "graph = graph_builder.compile()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e4029a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dispalaying the graph \n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5a92210b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-06-13T01:10:57.039805Z', 'done': True, 'done_reason': 'stop', 'total_duration': 5524330500, 'load_duration': 41460083, 'prompt_eval_count': 964, 'prompt_eval_duration': 3383553250, 'eval_count': 67, 'eval_duration': 2096142625, 'model_name': 'llama3.2'}, id='run--d00facc9-38f2-475f-b34a-e3009d255540-0', tool_calls=[{'name': 'tavily_search', 'args': {'exclude_domains': None, 'include_domains': None, 'include_images': False, 'query': 'StateGraph in LangGraph and its usefulness for building AI Agents', 'search_depth': 'advanced', 'time_range': None, 'topic': 'general'}, 'id': '3ca2497d-f074-4183-a98d-c2fb08b69037', 'type': 'tool_call'}], usage_metadata={'input_tokens': 964, 'output_tokens': 67, 'total_tokens': 1031})\n",
      "\n",
      "Assistent:  \n",
      "\n",
      "Assistent:  {\"query\": \"StateGraph in LangGraph and its usefulness for building AI Agents\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://adasci.org/a-practical-guide-to-building-ai-agents-with-langgraph/\", \"title\": \"A Practical Guide to Building AI Agents With LangGraph\", \"content\": \"Here, we are going to use LangGraph and build a customer support AI chat agent using gpt-3.5-turbo model. We are going to use LangGraph, where a StateGraph object defines the structure of our AI chat agent as a \\u201cstate machine\\u201d, which is either in a resting state or active state. We\\u2019ll add nodes to represent the LLM and functions our AI chat agent and user can call and edges to specify how the bot should transition between these functions. [...] uniquely suited for creating reliable, fault-tolerant agent-based systems. It uses StateGraph to define the states of agents and has the power of being able to loop, allowing for handling more ambiguous inputs than simple chains. In this article, we will break down what LangGraph is and see how we can build a customer support [AI Agent](https://adasci.org/genais-role-in-personalizing-edge-experiences/) using LangChain and support its runtimes through the LangGraph framework. [...] LangGraph simplifies AI agent development by focusing on three key components:\\n\\n**State:** The State is an accurate representation of the current status of the agent.\\n\\n**Node:** Nodes are the building blocks executing computations. The nodes can be LLM-based, [Python code](https://adasci.org/). Each graph execution builds a state, and this is passed between nodes during the execution. These nodes understand the state and update it with the new state after the execution.\", \"score\": 0.89053273, \"raw_content\": null}, {\"url\": \"https://realpython.com/langgraph-python/\", \"title\": \"LangGraph: Build Stateful AI Agents in Python - Real Python\", \"content\": \"**What is a state graph in LangGraph?**Show/Hide\\n\\nA state graph in LangGraph is a directed graph representation of LLM workflows, where nodes represent actions like function calls, and edges dictate the workflow\\u2019s sequence, enabling conditional and cyclic operations.\\n\\n**How do you create conditional workflows in LangGraph?**Show/Hide [...] *   You can use LangGraph to build LLM workflows by **defining state graphs with nodes and edges**.\\n*   LangGraph expands LangChain\\u2019s capabilities by providing tools to build complex LLM workflows with **state, conditional edges, and cycles**.\\n*   **LLM agents** in LangGraph autonomously process tasks using state graphs to make decisions and interact with tools or APIs.\\n*   You can use LangGraph independently of LangChain, although they\\u2019re often used together to complement each other. [...] [Remove ads](https://realpython.com/account/join/)\\n\\nLangGraph is a versatile Python library designed for stateful, cyclic, and multi-actor Large Language Model (LLM) applications. LangGraph builds upon its parent library, LangChain, and allows you to build sophisticated workflows that are capable of handling the complexities of real-world LLM applications.\\n\\n**By the end of this tutorial, you\\u2019ll understand that:**\", \"score\": 0.8858788, \"raw_content\": null}], \"response_time\": 2.24}\n",
      "AIMessage(content=\"A StateGraph in LangGraph is a directed graph representation of LLM workflows, where nodes represent actions like function calls, and edges dictate the workflow's sequence, enabling conditional and cyclic operations. It allows for building complex Large Language Model (LLM) workflows with state, conditional edges, and cycles.\\n\\nLangGraph uses StateGraph to define the states of agents and has the power of being able to loop, allowing for handling more ambiguous inputs than simple chains. This makes it uniquely suited for creating reliable, fault-tolerant agent-based systems.\\n\\nThe key components of LangGraph include:\\n\\n*   **State:** The State is an accurate representation of the current status of the agent.\\n*   **Node:** Nodes are the building blocks executing computations. The nodes can be LLM-based or Python code. Each graph execution builds a state, and this is passed between nodes during the execution.\\n\\nLangGraph simplifies AI agent development by focusing on these three key components. It allows you to build sophisticated workflows that can handle the complexities of real-world LLM applications.\", additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-06-13T01:11:09.610958Z', 'done': True, 'done_reason': 'stop', 'total_duration': 8856997250, 'load_duration': 38506375, 'prompt_eval_count': 888, 'prompt_eval_duration': 2340660167, 'eval_count': 211, 'eval_duration': 6455149208, 'model_name': 'llama3.2'}, id='run--8ee0b8fa-c210-4d6f-8a32-7a40a752903f-0', usage_metadata={'input_tokens': 888, 'output_tokens': 211, 'total_tokens': 1099})\n",
      "\n",
      "Assistent:  A StateGraph in LangGraph is a directed graph representation of LLM workflows, where nodes represent actions like function calls, and edges dictate the workflow's sequence, enabling conditional and cyclic operations. It allows for building complex Large Language Model (LLM) workflows with state, conditional edges, and cycles.\n",
      "\n",
      "LangGraph uses StateGraph to define the states of agents and has the power of being able to loop, allowing for handling more ambiguous inputs than simple chains. This makes it uniquely suited for creating reliable, fault-tolerant agent-based systems.\n",
      "\n",
      "The key components of LangGraph include:\n",
      "\n",
      "*   **State:** The State is an accurate representation of the current status of the agent.\n",
      "*   **Node:** Nodes are the building blocks executing computations. The nodes can be LLM-based or Python code. Each graph execution builds a state, and this is passed between nodes during the execution.\n",
      "\n",
      "LangGraph simplifies AI agent development by focusing on these three key components. It allows you to build sophisticated workflows that can handle the complexities of real-world LLM applications.\n",
      "\n",
      "Good Bye!!!\n"
     ]
    }
   ],
   "source": [
    "# ask the chatbot the questions\n",
    "from pprint import pprint\n",
    "\n",
    "def stream_graph_updates(user_input: str)->None:\n",
    "    initial_state = {\"messages\":[{\"role\": \"user\",\"content\": user_input}]}\n",
    "    for event in graph.stream(initial_state):\n",
    "        #pprint(event)\n",
    "        for value in event.values():\n",
    "            print(\"\\nAssistent: \", value.get('messages')[-1].content)\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"\\nUser: \").strip()\n",
    "\n",
    "        if user_input.lower() in ['q', 'exit', 'quit']:\n",
    "            print(\"\\nGood Bye!!!\")\n",
    "            break\n",
    "\n",
    "        stream_graph_updates(user_input=user_input)\n",
    "    except Exception as e:\n",
    "        user_input = \"What do you know about LangGraph?\"\n",
    "        print(\"User: \", user_input)\n",
    "        stream_graph_updates(user_input=user_input)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea56c3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
